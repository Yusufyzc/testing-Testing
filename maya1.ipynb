{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cadaea-bc8e-41a1-870d-1468c43935fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/3] Loading Maya1 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d049be35862c467b8f5818077382dc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: 156960 tokens in vocabulary\n",
      "\n",
      "[2/3] Loading SNAC audio decoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Yusuf Yazici\\anaconda3\\envs\\kumru\\Lib\\site-packages\\snac\\snac.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAC decoder loaded\n",
      "\n",
      "[3/3] Generating speech...\n",
      "Description: Over-exaggerated Bollywood-style male teen voice with hyper Indian accent. Super excited, fast-paced.\n",
      "Text: Helooooo dis is Amaazon Suppord dot caaam! How can I helping you?\n",
      "\n",
      "Prompt preview (first 200 chars):\n",
      "   '<custom_token_3><|begin_of_text|><description=\"Over-exaggerated Bollywood-style male teen voice with hyper Indian accent. Super excited, fast-paced.\"> Helooooo dis is Amaazon Suppord dot caaam! How ca'\n",
      "   Prompt length: 274 chars\n",
      "   Input token count: 52 tokens\n",
      "Generated 533 tokens\n",
      "   First 20 tokens: [132151, 134098, 138281, 143985, 147568, 149485, 154959, 132104, 133966, 137466, 142338, 147094, 151987, 153975, 129250, 132570, 138731, 141048, 148266, 150004]\n",
      "   Last 20 tokens: [138136, 144450, 146744, 148844, 156362, 129414, 135280, 140240, 144336, 145679, 149699, 153067, 130334, 133766, 136786, 142810, 146386, 152348, 154697, 128258]\n",
      " EOS token found at position 532/533\n",
      "Extracted 532 SNAC tokens\n",
      "   SNAC tokens in output: 532\n",
      "   Other tokens in output: 1\n",
      "   No SOS token found in generated output!\n",
      "Unpacked to 76 frames\n",
      "   L1: 76 codes\n",
      "   L2: 152 codes\n",
      "   L3: 304 codes\n",
      "\n",
      "[4/4] Decoding to audio...\n",
      "Audio generated: 153600 samples (6.40s)\n",
      "\n",
      "Voice generated successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from snac import SNAC\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "CODE_START_TOKEN_ID = 128257\n",
    "CODE_END_TOKEN_ID = 128258\n",
    "CODE_TOKEN_OFFSET = 128266\n",
    "SNAC_MIN_ID = 128266\n",
    "SNAC_MAX_ID = 156937\n",
    "SNAC_TOKENS_PER_FRAME = 7\n",
    "\n",
    "SOH_ID = 128259\n",
    "EOH_ID = 128260\n",
    "SOA_ID = 128261\n",
    "BOS_ID = 128000\n",
    "TEXT_EOT_ID = 128009\n",
    "\n",
    "\n",
    "def build_prompt(tokenizer, description: str, text: str) -> str:\n",
    "    \"\"\"Build formatted prompt for Maya1.\"\"\"\n",
    "    soh_token = tokenizer.decode([SOH_ID])\n",
    "    eoh_token = tokenizer.decode([EOH_ID])\n",
    "    soa_token = tokenizer.decode([SOA_ID])\n",
    "    sos_token = tokenizer.decode([CODE_START_TOKEN_ID])\n",
    "    eot_token = tokenizer.decode([TEXT_EOT_ID])\n",
    "    bos_token = tokenizer.bos_token\n",
    "    \n",
    "    formatted_text = f'<description=\"{description}\"> {text}'\n",
    "    \n",
    "    prompt = (\n",
    "        soh_token + bos_token + formatted_text + eot_token +\n",
    "        eoh_token + soa_token + sos_token\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def extract_snac_codes(token_ids: list) -> list:\n",
    "    \"\"\"Extract SNAC codes from generated tokens.\"\"\"\n",
    "    try:\n",
    "        eos_idx = token_ids.index(CODE_END_TOKEN_ID)\n",
    "    except ValueError:\n",
    "        eos_idx = len(token_ids)\n",
    "    \n",
    "    snac_codes = [\n",
    "        token_id for token_id in token_ids[:eos_idx]\n",
    "        if SNAC_MIN_ID <= token_id <= SNAC_MAX_ID\n",
    "    ]\n",
    "    \n",
    "    return snac_codes\n",
    "\n",
    "\n",
    "def unpack_snac_from_7(snac_tokens: list) -> list:\n",
    "    \"\"\"Unpack 7-token SNAC frames to 3 hierarchical levels.\"\"\"\n",
    "    if snac_tokens and snac_tokens[-1] == CODE_END_TOKEN_ID:\n",
    "        snac_tokens = snac_tokens[:-1]\n",
    "    \n",
    "    frames = len(snac_tokens) // SNAC_TOKENS_PER_FRAME\n",
    "    snac_tokens = snac_tokens[:frames * SNAC_TOKENS_PER_FRAME]\n",
    "    \n",
    "    if frames == 0:\n",
    "        return [[], [], []]\n",
    "    \n",
    "    l1, l2, l3 = [], [], []\n",
    "    \n",
    "    for i in range(frames):\n",
    "        slots = snac_tokens[i*7:(i+1)*7]\n",
    "        l1.append((slots[0] - CODE_TOKEN_OFFSET) % 4096)\n",
    "        l2.extend([\n",
    "            (slots[1] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[4] - CODE_TOKEN_OFFSET) % 4096,\n",
    "        ])\n",
    "        l3.extend([\n",
    "            (slots[2] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[3] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[5] - CODE_TOKEN_OFFSET) % 4096,\n",
    "            (slots[6] - CODE_TOKEN_OFFSET) % 4096,\n",
    "        ])\n",
    "    \n",
    "    return [l1, l2, l3]\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Load the best open source voice AI model\n",
    "    print(\"\\n[1/3] Loading Maya1 model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"maya-research/maya1\", \n",
    "        torch_dtype=torch.bfloat16, \n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"maya-research/maya1\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(f\"Model loaded: {len(tokenizer)} tokens in vocabulary\")\n",
    "    \n",
    "    # Load SNAC audio decoder (24kHz)\n",
    "    print(\"\\n[2/3] Loading SNAC audio decoder...\")\n",
    "    snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\").eval()\n",
    "    if torch.cuda.is_available():\n",
    "        snac_model = snac_model.to(\"cuda\")\n",
    "    print(\"SNAC decoder loaded\")\n",
    "    \n",
    "    # Design your voice with natural language\n",
    "    description = \"Over-exaggerated Bollywood-style male teen voice with hyper Indian accent. Super excited, fast-paced.\"\n",
    "    text = \"Helooooo dis is Amaazon Suppord dot caaam! How can I helping you?\"\n",
    "    \n",
    "    print(\"\\n[3/3] Generating speech...\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    \n",
    "    # Create prompt with proper formatting\n",
    "    prompt = build_prompt(tokenizer, description, text)\n",
    "    \n",
    "    # Debug: Show prompt details\n",
    "    print(f\"\\nPrompt preview (first 200 chars):\")\n",
    "    print(f\"   {repr(prompt[:200])}\")\n",
    "    print(f\"   Prompt length: {len(prompt)} chars\")\n",
    "    \n",
    "    # Generate emotional speech\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    print(f\"   Input token count: {inputs['input_ids'].shape[1]} tokens\")\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=2048,  # Increase to let model finish naturally\n",
    "            min_new_tokens=28,  # At least 4 SNAC frames\n",
    "            temperature=0.4, \n",
    "            top_p=0.9, \n",
    "            repetition_penalty=1.1,  # Prevent loops\n",
    "            do_sample=True,\n",
    "            eos_token_id=CODE_END_TOKEN_ID,  # Stop at end of speech token\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    # Extract generated tokens (everything after the input prompt)\n",
    "    generated_ids = outputs[0, inputs['input_ids'].shape[1]:].tolist()\n",
    "    \n",
    "    print(f\"Generated {len(generated_ids)} tokens\")\n",
    "    \n",
    "    # Debug: Check what tokens we got\n",
    "    print(f\"   First 20 tokens: {generated_ids[:20]}\")\n",
    "    print(f\"   Last 20 tokens: {generated_ids[-20:]}\")\n",
    "    \n",
    "    # Check if EOS was generated\n",
    "    if CODE_END_TOKEN_ID in generated_ids:\n",
    "        eos_position = generated_ids.index(CODE_END_TOKEN_ID)\n",
    "        print(f\" EOS token found at position {eos_position}/{len(generated_ids)}\")\n",
    "    \n",
    "    # Extract SNAC audio tokens\n",
    "    snac_tokens = extract_snac_codes(generated_ids)\n",
    "    \n",
    "    print(f\"Extracted {len(snac_tokens)} SNAC tokens\")\n",
    "    \n",
    "    # Debug: Analyze token types\n",
    "    snac_count = sum(1 for t in generated_ids if SNAC_MIN_ID <= t <= SNAC_MAX_ID)\n",
    "    other_count = sum(1 for t in generated_ids if t < SNAC_MIN_ID or t > SNAC_MAX_ID)\n",
    "    print(f\"   SNAC tokens in output: {snac_count}\")\n",
    "    print(f\"   Other tokens in output: {other_count}\")\n",
    "    \n",
    "    # Check for SOS token\n",
    "    if CODE_START_TOKEN_ID in generated_ids:\n",
    "        sos_pos = generated_ids.index(CODE_START_TOKEN_ID)\n",
    "        print(f\"   SOS token at position: {sos_pos}\")\n",
    "    else:\n",
    "        print(f\"   No SOS token found in generated output!\")\n",
    "    \n",
    "    if len(snac_tokens) < 7:\n",
    "        print(\"Error: Not enough SNAC tokens generated\")\n",
    "        return\n",
    "    \n",
    "    # Unpack SNAC tokens to 3 hierarchical levels\n",
    "    levels = unpack_snac_from_7(snac_tokens)\n",
    "    frames = len(levels[0])\n",
    "    \n",
    "    print(f\"Unpacked to {frames} frames\")\n",
    "    print(f\"   L1: {len(levels[0])} codes\")\n",
    "    print(f\"   L2: {len(levels[1])} codes\")\n",
    "    print(f\"   L3: {len(levels[2])} codes\")\n",
    "    \n",
    "    # Convert to tensors\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    codes_tensor = [\n",
    "        torch.tensor(level, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        for level in levels\n",
    "    ]\n",
    "    \n",
    "    # Generate final audio with SNAC decoder\n",
    "    print(\"\\n[4/4] Decoding to audio...\")\n",
    "    with torch.inference_mode():\n",
    "        z_q = snac_model.quantizer.from_codes(codes_tensor)\n",
    "        audio = snac_model.decoder(z_q)[0, 0].cpu().numpy()\n",
    "    \n",
    "    # Trim warmup samples (first 2048 samples)\n",
    "    if len(audio) > 2048:\n",
    "        audio = audio[2048:]\n",
    "    \n",
    "    duration_sec = len(audio) / 24000\n",
    "    print(f\"Audio generated: {len(audio)} samples ({duration_sec:.2f}s)\")\n",
    "    \n",
    "    # Save your emotional voice output\n",
    "    output_file = \"output.wav\"\n",
    "    sf.write(output_file, audio, 24000)\n",
    "    print(f\"\\nVoice generated successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d138b-2b82-4aa4-a64d-707197ad4753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c4781-7e43-4fc9-a64e-ae41ae8c51c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e439b7-fd3b-4036-adb9-259e15d800c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
